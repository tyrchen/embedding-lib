# embedding-lib

[![æ„å»ºçŠ¶æ€](https://github.com/tyrchen/embedding-lib/workflows/build/badge.svg)](https://github.com/tyrchen/embedding-lib/actions)
[![Crates.io](https://img.shields.io/crates/v/embedding-lib.svg)](https://crates.io/crates/embedding-lib)
[![æ–‡æ¡£](https://docs.rs/embedding-lib/badge.svg)](https://docs.rs/embedding-lib)

åŸºäº HuggingFace [text-embeddings-inference](https://github.com/huggingface/text-embeddings-inference) æ„å»ºçš„é«˜æ€§èƒ½æ–‡æœ¬åµŒå…¥åº“ï¼Œæä¾›åŸç”Ÿ Rust APIï¼Œç”¨äºä½¿ç”¨ Transformer æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚

## ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½**: åŸºäº HuggingFace ä¼˜åŒ–çš„ text-embeddings-inference åç«¯æ„å»º
- ğŸ¯ **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒ BAAI/bgeã€Qwenã€sentence-transformers å’Œå…¶ä»–çƒ­é—¨æ¨¡å‹
- âš¡ **ç¡¬ä»¶åŠ é€Ÿ**: æ”¯æŒ macOS ä¸Šçš„ Metal åŠ é€Ÿå’Œ NVIDIA GPU ä¸Šçš„ CUDA
- ğŸ”„ **çµæ´»çš„æ± åŒ–**: å¤šç§æ± åŒ–ç­–ç•¥ï¼ˆCLSã€Meanã€LastTokenã€Spladeï¼‰
- ğŸŒ **å¤šè¯­è¨€**: æ”¯æŒå¤šè¯­è¨€æ¨¡å‹å’Œæ–‡æœ¬å¤„ç†
- ğŸ›¡ï¸ **ç±»å‹å®‰å…¨**: å®Œæ•´çš„ Rust ç±»å‹å®‰å…¨ï¼Œå…·å¤‡ç»¼åˆé”™è¯¯å¤„ç†
- ğŸ“¦ **æ˜“äºé›†æˆ**: ç®€å•çš„å¼‚æ­¥ APIï¼Œé‡‡ç”¨æ„å»ºå™¨æ¨¡å¼é…ç½®

## å¿«é€Ÿå¼€å§‹

å°†ä»¥ä¸‹å†…å®¹æ·»åŠ åˆ°ä½ çš„ `Cargo.toml`:

```toml
[dependencies]
embedding-lib = { git = "https://github.com/tyrchen/embedding-lib", version = "0.1.0" }
tokio = { version = "1.0", features = ["full"] }
```

### åŸºç¡€ç”¨æ³•

```rust
use embedding_lib::{TextEmbeddings, TextEmbeddingsOptions};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // ä½¿ç”¨çƒ­é—¨åµŒå…¥æ¨¡å‹åˆå§‹åŒ–
    let options = TextEmbeddingsOptions::new("BAAI/bge-small-en-v1.5".to_string());
    let embedder = TextEmbeddings::new(options).await?;

    // ç”ŸæˆåµŒå…¥
    let texts = ["Hello world", "How are you?"];
    let embeddings = embedder.embed(&texts).await?;

    println!("ç”Ÿæˆäº† {} ä¸ªåµŒå…¥ï¼Œç»´åº¦ä¸º {}",
             embeddings.len(), embeddings[0].len());

    Ok(())
}
```

### é«˜çº§é…ç½®

```rust
use embedding_lib::{TextEmbeddings, TextEmbeddingsOptions};
use text_embeddings_backend::{DType, Pool};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let options = TextEmbeddingsOptions::new("Qwen/Qwen3-Embedding-0.6B".to_string())
        .with_dtype(DType::Float16)           // ä½¿ç”¨ FP16 æé«˜å†…å­˜æ•ˆç‡
        .with_pooling(Pool::Mean)             // ä½¿ç”¨å‡å€¼æ± åŒ–
        .with_max_concurrent_requests(128)    // è°ƒæ•´å¹¶å‘æ•°
        .with_max_batch_tokens(512)           // æ‰¹å¤„ç†å¤§å°ä¼˜åŒ–
        .with_hf_token("your-token".to_string()); // ç§æœ‰æ¨¡å‹

    let embedder = TextEmbeddings::new(options).await?;

    // ç”Ÿæˆæ ‡å‡†åŒ–åµŒå…¥ï¼ˆå•ä½å‘é‡ï¼‰
    let texts = ["Machine learning", "äººå·¥æ™ºèƒ½"];
    let embeddings = embedder.embed_normalized(&texts).await?;

    Ok(())
}
```

## æ¶æ„

```mermaid
graph TB
    A[ç”¨æˆ·åº”ç”¨ç¨‹åº] --> B[TextEmbeddings å®¢æˆ·ç«¯]
    B --> C[TextEmbeddingsOptions]
    B --> D[æ¨ç†å¼•æ“]
    D --> E[åˆ†è¯]
    D --> F[é˜Ÿåˆ—ç®¡ç†å™¨]
    D --> G[åç«¯]

    E --> H[HuggingFace Tokenizer]
    F --> I[è¯·æ±‚æ‰¹å¤„ç†]
    G --> J[æ¨¡å‹åŠ è½½]
    G --> K[ç¡¬ä»¶åŠ é€Ÿ]

    K --> L[Metal/CUDA/CPU]
    J --> M[HuggingFace Hub]
    J --> N[æœ¬åœ°æ¨¡å‹]

    subgraph "æ¨¡å‹ç±»å‹"
        O[BERT ç±»æ¨¡å‹]
        P[Qwen æ¨¡å‹]
        Q[Sentence Transformers]
        R[è‡ªå®šä¹‰æ¨¡å‹]
    end

    J --> O
    J --> P
    J --> Q
    J --> R
```

## æ¨¡å‹åŠ è½½å’Œåˆå§‹åŒ–

```mermaid
sequenceDiagram
    participant App as åº”ç”¨ç¨‹åº
    participant TE as TextEmbeddings
    participant Hub as HuggingFace Hub
    participant Backend as TEI åç«¯
    participant Model as æ¨¡å‹å¼•æ“

    App->>TE: new(options)
    TE->>Hub: ä¸‹è½½æ¨¡å‹æ–‡ä»¶
    Hub-->>TE: æ¨¡å‹æ–‡ä»¶
    TE->>TE: åŠ è½½ config.json
    TE->>TE: åˆå§‹åŒ–åˆ†è¯å™¨
    TE->>Backend: åˆ›å»ºåç«¯
    Backend->>Model: åŠ è½½æ¨¡å‹æƒé‡
    Model-->>Backend: æ¨¡å‹å°±ç»ª
    Backend->>Backend: æ¨¡å‹é¢„çƒ­
    Backend-->>TE: åç«¯å°±ç»ª
    TE->>TE: åˆ›å»ºæ¨ç†å¼•æ“
    TE-->>App: TextEmbeddings å®ä¾‹
```

## åµŒå…¥ç”Ÿæˆè¿‡ç¨‹

```mermaid
flowchart TD
    A[è¾“å…¥æ–‡æœ¬æ•°ç»„] --> B[è·å–è®¸å¯]
    B --> C[åˆ†è¯]
    C --> D[æ–‡æœ¬å¤„ç†]
    D --> E[æ¨¡å‹æ¨ç†]
    E --> F[æ± åŒ–ç­–ç•¥]
    F --> G{æ ‡å‡†åŒ–?}
    G -->|æ˜¯| H[L2 æ ‡å‡†åŒ–]
    G -->|å¦| I[åŸå§‹åµŒå…¥]
    H --> J[è¿”å›åµŒå…¥]
    I --> J

    subgraph "æ± åŒ–é€‰é¡¹"
        K[CLS Token]
        L[å‡å€¼æ± åŒ–]
        M[æœ«å°¾ Token]
        N[Splade]
    end

    F --> K
    F --> L
    F --> M
    F --> N
```

## æ”¯æŒçš„æ¨¡å‹

è¯¥åº“æ”¯æŒå¹¿æ³›çš„ Transformer æ¨¡å‹ï¼š

### çƒ­é—¨åµŒå…¥æ¨¡å‹

- **BAAI/bge-large-en-v1.5** - é«˜è´¨é‡è‹±æ–‡åµŒå…¥
- **BAAI/bge-small-en-v1.5** - å¿«é€Ÿè½»é‡çº§è‹±æ–‡æ¨¡å‹
- **sentence-transformers/all-MiniLM-L6-v2** - ç´§å‡‘é€šç”¨æ¨¡å‹
- **Qwen/Qwen3-Embedding-0.6B** - å¤šè¯­è¨€ Qwen åµŒå…¥æ¨¡å‹

### å¤šè¯­è¨€æ¨¡å‹

- **BAAI/bge-m3** - å¤šè¯­è¨€ BGE æ¨¡å‹
- **intfloat/multilingual-e5-large** - E5 å¤šè¯­è¨€åµŒå…¥
- **Alibaba-NLP/gte-Qwen2-1.5B-instruct** - æŒ‡ä»¤è°ƒä¼˜çš„ Qwen æ¨¡å‹

### ä¸“ç”¨æ¨¡å‹

- **jinaai/jina-embeddings-v2-base-en** - Jina AI åµŒå…¥
- **mixedbread-ai/mxbai-embed-large-v1** - é•¿ä¸Šä¸‹æ–‡åµŒå…¥
- **nomic-ai/nomic-embed-text-v1** - Nomic åµŒå…¥

## é…ç½®é€‰é¡¹

### TextEmbeddingsOptions

| é€‰é¡¹                      | ç±»å‹             | é»˜è®¤å€¼   | æè¿°                                |
|---------------------------|------------------|----------|-----------------------------------|
| `model_id`                | `String`         | å¿…éœ€     | HuggingFace æ¨¡å‹ ID æˆ–æœ¬åœ°è·¯å¾„      |
| `revision`                | `Option<String>` | `"main"` | æ¨¡å‹ç‰ˆæœ¬ï¼ˆåˆ†æ”¯/æ ‡ç­¾/æäº¤ï¼‰            |
| `dtype`                   | `Option<DType>`  | è‡ªåŠ¨     | æ•°æ®ç±»å‹ï¼ˆFloat16ã€Float32ã€BFloat16ï¼‰  |
| `pooling`                 | `Option<Pool>`   | è‡ªåŠ¨     | æ± åŒ–ç­–ç•¥ï¼ˆClsã€Meanã€LastTokenã€Spladeï¼‰ |
| `max_concurrent_requests` | `usize`          | 512      | æœ€å¤§å¹¶å‘è¯·æ±‚æ•°                      |
| `max_batch_tokens`        | `usize`          | 16384    | æ¯æ‰¹æ¬¡æœ€å¤§ token æ•°                 |
| `max_batch_requests`      | `Option<usize>`  | è‡ªåŠ¨     | æ¯æ‰¹æ¬¡æœ€å¤§è¯·æ±‚æ•°                    |
| `hf_token`                | `Option<String>` | None     | HuggingFace è®¤è¯ä»¤ç‰Œ                |
| `auto_truncate`           | `bool`           | `false`  | è‡ªåŠ¨æˆªæ–­é•¿æ–‡æœ¬                      |

### ç¡¬ä»¶åŠ é€Ÿ

è¯¥åº“è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å¯ç”¨çš„ç¡¬ä»¶åŠ é€Ÿï¼š

- **Metal** (macOS): Apple Silicon ä¸Šçš„è‡ªåŠ¨æ£€æµ‹
- **CUDA** (NVIDIA GPU): éœ€è¦å®‰è£… CUDA
- **CPU**: ä¼˜åŒ–çš„ CPU æ¨ç†ä½œä¸ºåå¤‡

## æ€§èƒ½æ³¨æ„äº‹é¡¹

### å†…å­˜ä½¿ç”¨

- ä½¿ç”¨ `DType::Float16` å¯å‡å°‘çº¦50%çš„å†…å­˜ä½¿ç”¨
- æ ¹æ®å¯ç”¨ GPU å†…å­˜è°ƒæ•´ `max_batch_tokens`
- åœ¨é€‰æ‹©æ¨¡å‹å˜ä½“æ—¶è€ƒè™‘æ¨¡å‹å¤§å°

### ååé‡ä¼˜åŒ–

- åœ¨é«˜ååé‡åœºæ™¯ä¸­å¢åŠ  `max_concurrent_requests`
- å¯¹å¤šä¸ªæ–‡æœ¬ä½¿ç”¨ `embed()` æ–¹æ³•è¿›è¡Œæ‰¹å¤„ç†
- å¯ç”¨ `auto_truncate` ä»¥è·å¾—ä¸€è‡´çš„æ€§èƒ½

### æ¨¡å‹é€‰æ‹©

- **å°æ¨¡å‹** (`bge-small`ã€`all-MiniLM`): æ¨ç†å¿«ï¼Œè´¨é‡è¾ƒä½
- **å¤§æ¨¡å‹** (`bge-large`ã€`gte-large`): è´¨é‡æ›´å¥½ï¼Œæ¨ç†è¾ƒæ…¢
- **ä¸“ç”¨æ¨¡å‹**: æ ¹æ®ç‰¹å®šç”¨ä¾‹é€‰æ‹©

## ç¤ºä¾‹

### è¯­ä¹‰æœç´¢

```rust
use embedding_lib::{TextEmbeddings, TextEmbeddingsOptions};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let options = TextEmbeddingsOptions::new("BAAI/bge-small-en-v1.5".to_string());
    let embedder = TextEmbeddings::new(options).await?;

    // ç´¢å¼•æ–‡æ¡£
    let documents = [
        "The cat sits on the mat",
        "A dog runs in the park",
        "Birds fly in the sky"
    ];
    let doc_embeddings = embedder.embed_normalized(&documents).await?;

    // æœç´¢æŸ¥è¯¢
    let query = "Animals playing outside";
    let query_embedding = &embedder.embed_normalized(&[query]).await?[0];

    // è®¡ç®—ç›¸ä¼¼åº¦
    let similarities: Vec<f32> = doc_embeddings.iter()
        .map(|doc_emb| cosine_similarity(query_embedding, doc_emb))
        .collect();

    // æ‰¾åˆ°æœ€ä½³åŒ¹é…
    let best_match = similarities.iter()
        .enumerate()
        .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
        .unwrap();

    println!("æœ€ä½³åŒ¹é…: \"{}\" (ç›¸ä¼¼åº¦: {:.3})",
             documents[best_match.0], best_match.1);

    Ok(())
}

fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let magnitude_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let magnitude_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    dot_product / (magnitude_a * magnitude_b)
}
```

### å¤šè¯­è¨€å¤„ç†

```rust
use embedding_lib::{TextEmbeddings, TextEmbeddingsOptions};
use text_embeddings_backend::Pool;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let options = TextEmbeddingsOptions::new("Qwen/Qwen3-Embedding-0.6B".to_string())
        .with_pooling(Pool::Mean);

    let embedder = TextEmbeddings::new(options).await?;

    let texts = [
        "Hello world",           // è‹±è¯­
        "Bonjour le monde",      // æ³•è¯­
        "ä½ å¥½ä¸–ç•Œ",               // ä¸­æ–‡
        "Hola mundo",            // è¥¿ç­ç‰™è¯­
    ];

    let embeddings = embedder.embed_normalized(&texts).await?;

    println!("ç”Ÿæˆäº† {} ä¸ªå¤šè¯­è¨€åµŒå…¥", embeddings.len());

    Ok(())
}
```

## é”™è¯¯å¤„ç†

è¯¥åº“æä¾›äº†å…¨é¢çš„é”™è¯¯ç±»å‹ï¼š

```rust
use embedding_lib::{EmbeddingError, TextEmbeddings, TextEmbeddingsOptions};

#[tokio::main]
async fn main() {
    let options = TextEmbeddingsOptions::new("invalid-model".to_string());

    match TextEmbeddings::new(options).await {
        Ok(embedder) => {
            // ä½¿ç”¨åµŒå…¥å™¨
        },
        Err(EmbeddingError::Model(msg)) => {
            eprintln!("æ¨¡å‹é”™è¯¯: {}", msg);
        },
        Err(EmbeddingError::Config(msg)) => {
            eprintln!("é…ç½®é”™è¯¯: {}", msg);
        },
        Err(EmbeddingError::Inference(err)) => {
            eprintln!("æ¨ç†é”™è¯¯: {}", err);
        },
        Err(err) => {
            eprintln!("å…¶ä»–é”™è¯¯: {}", err);
        }
    }
}
```

## ä»æºç æ„å»º

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/tyrchen/embedding-lib.git
cd embedding-lib

# æ„å»ºåº“
cargo build --release

# è¿è¡Œæµ‹è¯•
cargo test

# è¿è¡Œç¤ºä¾‹
cargo run --example basic_usage
cargo run --example qwen_example
```

### å¼€å‘ä¾èµ–

å¯¹äº macOS ä¸Šçš„ Metal åŠ é€Ÿï¼š

```bash
# ç¡®ä¿å·²å®‰è£… Xcode å‘½ä»¤è¡Œå·¥å…·
xcode-select --install
```

å¯¹äº CUDA æ”¯æŒï¼š

```bash
# å®‰è£… CUDA å·¥å…·åŒ…ï¼ˆå»ºè®® 11.8+ ç‰ˆæœ¬ï¼‰
# æŒ‰ç…§ NVIDIA ä¸ºä½ çš„å¹³å°æä¾›çš„å®‰è£…æŒ‡å—
```

## è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£æŒ‡å—ã€‚

### å¼€å‘è®¾ç½®

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. è¿›è¡Œæ›´æ”¹
4. ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•
5. ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
6. æäº¤ pull request

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
cargo test

# å¸¦æ—¥å¿—è¿è¡Œ
RUST_LOG=debug cargo test

# è¿è¡Œç‰¹å®šæµ‹è¯•
cargo test test_options_builder
```

## è®¸å¯è¯

æœ¬é¡¹ç›®æ ¹æ® MIT è®¸å¯è¯æ¡æ¬¾åˆ†å‘ã€‚

æŸ¥çœ‹ [LICENSE.md](LICENSE.md) äº†è§£è¯¦æƒ…ã€‚

ç‰ˆæƒæ‰€æœ‰ 2025 Tyr Chen

## è‡´è°¢

- [HuggingFace](https://huggingface.co/) æä¾›çš„ä¼˜ç§€ text-embeddings-inference åç«¯
- Rust ç¤¾åŒºæä¾›çš„å‡ºè‰²å¼‚æ­¥å’Œæœºå™¨å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿ
- æœ¬åº“çš„æ‰€æœ‰è´¡çŒ®è€…å’Œç”¨æˆ·
